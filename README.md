# End-to-End Data Engineering Project with dbt, Snowflake 

## ğŸ“Œ Overview
This project demonstrates a **complete data engineering pipeline** built using:
- **dbt (Data Build Tool)** for SQL-based data transformations and modeling
- **Snowflake** as the cloud data warehouse
- **Apache Airflow** for workflow orchestration and scheduling
- **Python** for automation and scripting

The pipeline covers:
1. **Data Ingestion** â€“ loading raw data into Snowflake  
2. **Transformation** â€“ building staging, intermediate, and mart layers with dbt  
3. **Orchestration** â€“ scheduling and monitoring workflows using Apache Airflow  

---

## âš™ï¸ Tech Stack
- **dbt Core** â€“ SQL transformations, data models, testing, and documentation  
- **Snowflake** â€“ scalable, cloud-native data warehouse  
- **Apache Airflow** â€“ DAG-based workflow orchestration  
- **Python** â€“ scripting and automation logic  
- **Git/GitHub** â€“ version control and collaboration  

---

## ğŸ“‚ Project Structure
snowflake_data_project/
â”‚â”€â”€ models/ # dbt models (staging, marts, transformations)
â”‚â”€â”€ dags/ # Airflow DAGs for scheduling workflows
â”‚â”€â”€ logs/ # Airflow logs
â”‚â”€â”€ seeds/ # Sample seed data for dbt
â”‚â”€â”€ macros/ # Custom dbt macros
â”‚â”€â”€ dbt_project.yml # Main dbt configuration file
â”‚â”€â”€ README.md # Documentation



---

## ğŸš€ Setup & Installation

### 1. Clone the Repository

```bash
git clone https://github.com/kirlosmagdy/dbt_snowflake_project.git
cd dbt_snowflake_project
```

### 2. Set Up Virtual Environment

```bash
python -m venv venv        # Activate venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3. Configure dbt Connection to Snowflake

Update the profiles.yml file in ~/.dbt/ with your Snowflake credentials:

snowflake_project:
  outputs:
    dev:
      type: snowflake
      account: your_snowflake_account
      database: finance_db
      user: dbt_user
      password: your_password
      warehouse: finance_wh
      role: ACCOUNTADMIN
      schema: raw
  target: dev


### 4. Run dbt Models

```bash
dbt run        # Build models
dbt test       # Run tests to validate data integrity
```

## ğŸ“Š Data Flow

1- Raw data ingestion â†’ Snowflake raw schema
2- Staging models â†’ Cleaned and structured layer in Snowflake
3- Marts layer â†’ Business-focused tables for analytics and reporting
